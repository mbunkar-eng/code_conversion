# LLM Code Pipeline Configuration
# Copy this file to .env and configure as needed

# =============================================================================
# API Settings
# =============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# =============================================================================
# Authentication
# =============================================================================
# Single API key
LLM_API_KEY=

# Multiple API keys (comma-separated)
# LLM_API_KEYS=key1,key2,key3

# File containing API keys (one per line)
# LLM_API_KEYS_FILE=/path/to/api_keys.txt

# =============================================================================
# Model Settings
# =============================================================================
# Path to local model or HuggingFace repo
MODEL_PATH=Qwen/Qwen2.5-Coder-7B-Instruct

# Directory for downloaded models
MODELS_DIR=./downloaded_models

# Default model to use
DEFAULT_MODEL=qwen2.5-coder-7b

# =============================================================================
# Inference Settings
# =============================================================================
# Number of GPUs for tensor parallelism
TENSOR_PARALLEL_SIZE=1

# GPU memory utilization (0.0 - 1.0)
GPU_MEMORY_UTILIZATION=0.9

# Maximum model context length (leave empty for model default)
MAX_MODEL_LEN=

# Data type: float16, bfloat16, float32
DTYPE=float16

# Quantization method: awq, gptq, or leave empty
QUANTIZATION=

# =============================================================================
# Generation Defaults
# =============================================================================
DEFAULT_MAX_TOKENS=2048
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.95

# =============================================================================
# HuggingFace
# =============================================================================
# HuggingFace token for private models
HF_TOKEN=

# HuggingFace cache directory
# HF_HOME=~/.cache/huggingface

# =============================================================================
# Logging
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Use JSON format for logs
JSON_LOGS=false

# Log file path (leave empty for stdout only)
LOG_FILE=

# =============================================================================
# CORS
# =============================================================================
# Allowed origins (comma-separated, * for all)
CORS_ORIGINS=*

# =============================================================================
# Development/Testing
# =============================================================================
# Enable mock mode (no GPU required)
LLM_PIPELINE_MOCK_MODE=false
